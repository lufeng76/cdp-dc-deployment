= Troubleshoots

== CMS not working

CMS were not starting well, hence, no metrics and no status were available

Checking to logs showed that CMS were not able to poll from CM, and CM was running out of memory with long GC pauses...

A raise of max JVM heap (to 4GB) for CM has been made on file: __/etc/default/cloudera-scm-server__ , then a restart of CM and finally using CM UI, a restart of CMS.


== YARN queue Manager is not supported anymore

Configuration changes is not permitted as it's still old versions, then it is recommended to upgrade ASAP CDH parcel to 7.1.1.

Solution is to remove this service, as it leads to an inconsistent state of different services if not, thus not allowing the upgrade to take place.

However, when trying to do the upgrade, a message error will appear: "Failed to upgrade cluster: A service of type QUEUEMANAGER must be installed on the cluster prior to upgrade to version CDH 7.1.1.". 

To overcome this, "Manual upgrade" has been choosen and hence a manual restart of services has been made after.


== CM not stable

It took some restarts to get a stable CM, as it was using a huge amount of memory trying to reconstruct, resend descriptors to all CMS.

Solution is to wait and keep an eye on logs of CM.


== SolR needs migration

There is this message blocking upgrade: "message.cluster.upgrade.solr.solr71.missing_solr_migration" as it does not allow migration.

Stop SolR
Reinitialize SolR for upgrade 
Initialize SolR
SolR > Configuration > Set SolR server for upgrade

Once these steps have been done, there is no more this message, however this one appears after Service Inspector ran: "Specified metadata directory path Missing directory: /var/lib/upgrade/c6_config"

On the node were SolR server is running:

As these were run before stop and reinit of SolR:
[source,bash]
mkdir $HOME/cdh7-solr-migration
/opt/cloudera/cm/solr-upgrade/solr-upgrade.sh download-metadata -d $HOME/cdh7-solr-migration

A simple copy of metadata was made:
[source,bash]
mkdir -p /var/lib/upgrade/c6_config
cp -r cdh7-migrated-solr-config/* /var/lib/upgrade/c6_config
chown -R solr:solr /var/lib/upgrade/c6_config


== Hive metastore not upgraded

Hive metastore server is not running due to:

[source,bash]
2020-03-31 01:11:48,793 ERROR org.apache.hadoop.hive.metastore.HiveMetaStore: [main]: MetaException(message:Hive Schema version 3.1.3000.7.1.1.0-338 does not match metastore's schema version 3.1.2000 Metastore is not upgraded or corrupt)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:84)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:93)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:10010)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:10005)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.startMetaStore(HiveMetaStore.java:10286)
	at org.apache.hadoop.hive.metastore.HiveMetaStore.main(HiveMetaStore.java:10203)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:318)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:232)
Caused by: MetaException(message:Hive Schema version 3.1.3000.7.1.1.0-338 does not match metastore's schema version 3.1.2000 Metastore is not upgraded or corrupt)

Solution is to upgrade manually Hive metastore:
First:
[source,bash]
metastore=# create domain clob as text;
CREATE DOMAIN

Then run these commands to run all needed files:
[source,bash]
psql metastore -U postgres -W -f /opt/cloudera/parcels/CDH/lib/hive/scripts/metastore/upgrade/postgres/hive-schema-3.1.3000.postgres.sql
psql metastore -U postgres -W -f /opt/cloudera/parcels/CDH/lib/hive/scripts/metastore/upgrade/postgres/hive-txn-schema-2.3.0.postgres.sql
psql metastore -U postgres -W -f /opt/cloudera/parcels/CDH/lib/hive/scripts/metastore/upgrade/postgres/upgrade-3.1.2000-to-3.1.3000.postgres.sql
psql metastore -U postgres -W -f /opt/cloudera/parcels/CDH/lib/hive/scripts/metastore/upgrade/postgres/upgrade-3.1.3000-to-3.1.3000.7.1.0.0.postgres.sql
psql metastore -U postgres -W -f /opt/cloudera/parcels/CDH/lib/hive/scripts/metastore/upgrade/postgres/upgrade-3.1.3000.7.1.0.0-to-3.1.3000.7.1.1.0.postgres.sql


CAUTION: It is not stated but it is required to have PostgreSQL 9.6 at least as some functions or types may not exists in default 9.2. 

Note that, as scripts were run with postgres user, it has been necessary to grant hive use priveleges and ownership on tables created:
[source,bash]
metastore=# ALTER TABLE "SCHEDULED_EXECUTIONS" OWNER TO hive;
ALTER TABLE
metastore=# ALTER TABLE "SCHEDULED_QUERIES" OWNER TO hive;
ALTER TABLE
metastore=# ALTER TABLE "CDH_VERSION" OWNER TO hive;
ALTER TABLE
metastore=# GRANT ALL ON TABLE "SCHEDULED_EXECUTIONS" TO hive;
GRANT
metastore=# GRANT ALL ON TABLE "SCHEDULED_QUERIES" TO hive;
GRANT
metastore=# GRANT ALL ON TABLE "CDH_VERSION" TO hive;
GRANT

After a restart of Hive Metastore, new errors came up, see below.

== Hive Metastore 

[source,bash]
2020-03-31 02:37:48,252 WARN  org.apache.hadoop.hive.metastore.txn.TxnHandler: [pool-7-thread-9]: Aborting timed out transactions failed due to ERROR: column "TXN_LAST_HEARTBEAT" does not exist
  Position: 82 (SQLState=42703, ErrorCode=0)
org.postgresql.util.PSQLException: ERROR: column "TXN_LAST_HEARTBEAT" does not exist

[source,bash]
metastore=> ALTER TABLE txns ADD COLUMN "TXN_LAST_HEARTBEAT" bigint;
ALTER TABLE


== Hive metastore unable to flush

[source,bash]
----
2020-03-31 02:37:04,445 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler: [pool-6-thread-133]: HMSHandler Fatal error: javax.jdo.JDODataStoreException: Exception thrown flushing changes to datastore
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543)

NestedThrowablesStackTrace:
java.sql.BatchUpdateException: Batch entry 0 DELETE FROM "CTLGS" WHERE "CTLG_ID"=9511 was aborted.  Call getNextException to see the cause.
----

and 

[source,bash]
2020-03-31 02:37:04,449 INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit: [pool-6-thread-133]: ugi=hue/cdp-test-1.gce.cloudera.com@FRISCH.COM	ip=172.31.116.157	cmd=create_catalog: Catalog(name:cloudera_manager_metastore_canary_test_catalog_hive_HIVEMETASTORE_5951829d225d4892e1b2c69ff99abb7a, locationUri:/user/hue/.cloudera_manager_hive_metastore_canary/cloudera_manager_metastore_canary_test_catalog_hive_HIVEMETASTORE_5951829d225d4892e1b2c69ff99abb7a)	
2020-03-31 02:37:04,451 ERROR org.apache.hadoop.hive.metastore.RetryingHMSHandler: [pool-6-thread-133]: AlreadyExistsException(message:Catalog cloudera_manager_metastore_canary_test_catalog_hive_HIVEMETASTORE_5951829d225d4892e1b2c69ff99abb7a already exists)


=> Both seemed linked (first one leads to the second one), hence Hive metastore was stopped and following changes were made:

Drop table DBS on cascade +
Recreate it with constraints but NOT constraint CTLGS +

[source,bash]
----
metastore=> DROP TABLE "DBS" CASCADE;
NOTICE:  drop cascades to 5 other objects
DETAIL:  drop cascades to constraint DATABASE_PARAMS_DB_ID_fkey on table "DATABASE_PARAMS"
drop cascades to constraint DB_PRIVS_DB_ID_fkey on table "DB_PRIVS"
drop cascades to constraint TBLS_DB_ID_fkey on table "TBLS"
drop cascades to constraint FUNCS_FK1 on table "FUNCS"
drop cascades to constraint I_SCHEMA_DB_ID_fkey on table "I_SCHEMA"
DROP TABLE
metastore=> CREATE TABLE "DBS" (
metastore(>     "DB_ID" bigint NOT NULL,
metastore(>     "DESC" character varying(4000) DEFAULT NULL::character varying,
metastore(>     "DB_LOCATION_URI" character varying(4000) NOT NULL,
metastore(>     "NAME" character varying(128) DEFAULT NULL::character varying,
metastore(>     "OWNER_NAME" character varying(128) DEFAULT NULL::character varying,
metastore(>     "OWNER_TYPE" character varying(10) DEFAULT NULL::character varying,
metastore(>     "CTLG_NAME" varchar(256),
metastore(>     "CREATE_TIME" BIGINT
metastore(> );
CREATE TABLE
metastore=> ALTER TABLE ONLY "DBS"
metastore->     ADD CONSTRAINT "DBS_pkey" PRIMARY KEY ("DB_ID");
NOTICE:  ALTER TABLE / ADD PRIMARY KEY will create implicit index "DBS_pkey" \for table "DBS"
ALTER TABLE
metastore=> ALTER TABLE ONLY "DATABASE_PARAMS"
metastore->     ADD CONSTRAINT "DATABASE_PARAMS_DB_ID_fkey" FOREIGN KEY ("DB_ID") REFERENCES "DBS"("DB_ID") DEFERRABLE;
ALTER TABLE
metastore=> ALTER TABLE ONLY "FUNCS"
metastore->     ADD CONSTRAINT "FUNCS_FK1" FOREIGN KEY ("DB_ID") REFERENCES "DBS" ("DB_ID") DEFERRABLE;
ALTER TABLE

----

Restart of hive metastore made it work.

However, it seems stucked in an infinite loop:

[source,bash]
2020-03-31 05:26:38,784 INFO  org.apache.hadoop.hive.metastore.txn.TxnHandler: [pool-11-thread-7]: Removed aborted transactions: ([7383]) from MIN_HISTORY_LEVEL
2020-03-31 05:26:38,784 INFO  org.apache.hadoop.hive.metastore.txn.TxnHandler: [pool-11-thread-7]: Aborted 0 transactions due to timeout
2020-03-31 05:26:38,784 INFO  org.apache.hadoop.hive.metastore.txn.TxnHandler: [pool-11-thread-7]: Removed aborted transactions: ([7383]) from MIN_HISTORY_LEVEL
2020-03-31 05:26:38,785 INFO  org.apache.hadoop.hive.metastore.txn.TxnHandler: [pool-11-thread-7]: Aborted 0 transactions due to timeout

Solution was to add two properties to Hive-site.xml via CM UI for Hive metastore:

hive.direct.sql.max.query.length to 1 +
hive.direct.sql.max.elements.in.clause to 1000

See link:https://issues.apache.org/jira/browse/HIVE-15181[https://issues.apache.org/jira/browse/HIVE-15181]

and Ranger error:

[source,bash]
2020-03-31 02:37:16,813 ERROR org.apache.ranger.admin.client.RangerAdminRESTClient: [Thread-17]: Failed to get response, Error is : TrustManager is not specified
2020-03-31 02:37:16,813 ERROR org.apache.ranger.admin.client.RangerAdminRESTClient: [Thread-17]: Error getting Roles; Received NULL response!!. secureMode=true, user=hive/cdp-test-1.gce.cloudera.com@FRISCH.COM (auth:KERBEROS), serviceName=cm_hive

=> This error is due to the fact that Ranger plugin requires a truststore configured.
Configured it into: /opt/cloudera/parcels/CDH/lib/ranger-hive-plugin/install.properties 
Have to make a changes into Hive to get a new redeployment.


== HS2 have no Tez jar

Error was: Caused by: java.io.FileNotFoundException: File does not exist: hdfs://hdfs-osiris/user/tez/0.9.1.7.1.1.0-338/tez.tar.gz

This was solved by deploying Tez jar files to HDFS with: Tez > Actions > Upload Tez tar file to HDFS.


== Ozone OM & SCM down

OM was down due to SCM not up as showed error:
[source,bash]
2020-03-31 01:11:04,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: cdp-test-2.gce.cloudera.com/172.31.115.219:9863. Already tried 49 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=50, sleepTime=1000 MILLISECONDS)
2020-03-31 01:11:04,398 WARN org.apache.hadoop.hdds.utils.RetriableTask: Execution of task OM#getScmInfo failed permanently after 10 attempts
java.net.ConnectException: Call From cdp-test-2.gce.cloudera.com/172.31.115.219 to cdp-test-2.gce.cloudera.com:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused

SCM was down due to following error:
[source,bash]
2020-03-31 01:02:21,353 INFO org.apache.hadoop.hdds.scm.container.placement.algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2020-03-31 01:02:21,456 ERROR org.apache.hadoop.hdds.scm.server.StorageContainerManagerStarter: SCM start failed with exception
com.google.protobuf.InvalidProtocolBufferException: Message missing required fields: id, members[0].uuid, members[0].ipAddress, members[0].hostName
	at com.google.protobuf.UninitializedMessageException.asInvalidProtocolBufferException(UninitializedMessageException.java:81)


Remove SCM & add it to another node made the trick, however OM was still down and DN were down due to "SCM version info mismatch". 

=> Solution was to apply what was already applied in link:99_Troubleshots.adoc[99_Troubleshots.adoc].

== Ozone DNs asks for HTTP.keytab

Following commands have been issued on all DNs:
[source,bash]
mkdir -p /etc/security/keytabs/
chmod 755 /etc/security/keytabs/
cd /run/cloudera-scm-agent/process/
cd `ls -t1 | grep -e "-OZONE" | head -1`
cp ozone.keytab /etc/security/keytabs/HTTP.keytab
chmod 400 /etc/security/keytabs/HTTP.keytab
chown hdfs:hdfs /etc/security/keytabs/HTTP.keytab

Also, a total cleaning of Ozone files has been made as it seems otherwise it leads to inconsistent states of DN.

== HBase master & Spark History server are not starting due to SSL

Error is in logs: +
 Caused by: java.lang.IllegalStateException: KeyStores with multiple certificates are not supported on the base class org.eclipse.jetty.util.ssl.SslContextFactory. (Use org.eclipse.jetty.util.ssl.SslContextFactory$Server or org.eclipse.jetty.util.ssl.SslContextFactory$Client instead)

In node 1, effectively, the keystore was created with morer than one certificate, due to manipulation error..

Suppression of useless certificates in keystore on nodee 1 combined with a restart of thrift server made it work for HBase master.



== Thrift server is blocked to launch

Supervisor was unable to launch thrift server, hence another one was added on node 2 and first one was removed, once Hue configuration was updated to use the new one.

== Oozie server library check

Error in CM is: 
"Bad : The Oozie Server build version(5.1.0.7.1.1.0-338) and the Oozie Server shared library version(5.1.0.7.0.3.0-79) do not match."

Oozie > Actions > Install Share lib

Above action fixed the error.


== Atlas can not initialize

Atlas could not initialize, stating that: 
[source,bash]
[E] 'admin' not found in /var/run/cloudera-scm-agent/process/1546348617-atlas-ATLAS_SERVER-InitializeAtlasRole/conf/users-credentials.properties file while Updating....!!

Effectively, file was empty on ADMIN line, so add the one taken from /opt/cloudera/parcels/CDH/etc/atlas/conf.dist/users-credentials.properties





